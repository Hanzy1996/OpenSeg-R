_BASE_: ../maskformer2_R50_bs16_50ep.yaml
MODEL:
  WEIGHTS: ./pretrained/maftp_l_pano.pth
  META_ARCHITECTURE: "MAFT_Plus_Reason"
  TEST_CLASS_REASON_JSON: "reason_data/general_reason/coco_class_des.json"
  REASON_DIR: "reason_data/image_reason/Qwen2.5-VL-72B-Instruct-AWQ"
  REASON_DATA: "coco-stuff"
  NUM_DES: 3
  CLIP_TYPE: "Convnext-L"
  CLASS_NAME_JSON: "dataset_cat/ade150.json"
  SEM_SEG_HEAD:
    NAME: "FCCLIPHead_Reason"
    NUM_CLASSES: 133
  FC_CLIP:
    CLIP_MODEL_NAME: "convnext_large_d_320"  
    CLIP_PRETRAINED_WEIGHTS: "laion2b_s29b_b131k_ft_soup" 
    EMBED_DIM: 768
    GEOMETRIC_ENSEMBLE_ALPHA: -1.
    GEOMETRIC_ENSEMBLE_BETA: -1.
  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MultiScaleMaskedTransformerDecoder_Reason"
    TEST:
      PANOPTIC_ON: True
  rc_weights: 0.1

INPUT:
  DATASET_MAPPER_NAME: "coco_panoptic_lsj" # mask_former_semantic coco_panoptic_lsj

DATASETS:
  TRAIN: ("coco_seg_pan_voab",) 
  TEST: ('openvocab_ade20k_panoptic_val', ) 


OUTPUT_DIR: ./out/panoptic/evaluation_reason
